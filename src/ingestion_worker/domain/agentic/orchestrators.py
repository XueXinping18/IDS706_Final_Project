"""
Agentic Workflow ç¼–æ’å™¨

èŒè´£ï¼š
- åˆ›å»º Cached Content
- å¹¶å‘å¤„ç† segments
- é™çº§ç­–ç•¥ï¼ˆå¤šæ¨¡æ€ â†’ çº¯æ–‡æœ¬ï¼‰
- èšåˆç»“æœ
- å†³å®šä½•æ—¶å‘é€é€šçŸ¥

ä¾èµ–ï¼š
- VertexClient (Infrastructure)
- Database (Infrastructure)
- LarkClient (Infrastructure)
- MCPTools (Domain)
- Annotators (Domain)
"""
import asyncio
from typing import Optional

from vertexai.preview.caching import CachedContent

from ingestion_worker.config import Config
from ingestion_worker.infrastructure.vertex import VertexClient, VertexError
from ingestion_worker.infrastructure.database import Database
from ingestion_worker.infrastructure.lark import LarkClient
from ingestion_worker.domain.agentic.mcp_tools import MCPTools
from ingestion_worker.domain.agentic.annotators.base import BaseAnnotator
from ingestion_worker.domain.agentic.annotators.word import WordAnnotator
from ingestion_worker.domain.agentic.annotators.phrase import PhraseAnnotator
from ingestion_worker.utils.logging import get_logger


class AgenticOrchestrator:
    """Agentic å·¥ä½œæµç¼–æ’å™¨"""

    # [æ–°å¢] é›†ä¸­å®šä¹‰çš„ç³»ç»ŸæŒ‡ä»¤ï¼Œç¡®ä¿æ¨¡å‹"ç‰¢è®°"å·¥å…·ä½¿ç”¨è§„åˆ™
    SYSTEM_INSTRUCTION = """
ä½ æ˜¯è§†é¢‘å†…å®¹åˆ†æä¸“å®¶ã€‚ä½ å°†çœ‹åˆ°å®Œæ•´çš„è§†é¢‘å’Œå­—å¹•ï¼ˆæˆ–ä»…å­—å¹•ï¼‰ã€‚

ä»»åŠ¡ï¼š
é€ä¸ªå¤„ç† Segmentï¼Œè¯†åˆ«å…¶ä¸­çš„å•è¯å’ŒçŸ­è¯­ï¼Œå¹¶**å¿…é¡»è°ƒç”¨ query_fine_units å·¥å…·**æŸ¥è¯¢æ•°æ®åº“ä¸­çš„å€™é€‰ï¼Œæ³¨æ„æŸ¥è¯¢æ•°æ®åº“æ—¶å¾€å¾€éœ€è¦å•è¯çŸ­è¯­çš„åŸå‹ã€‚
æ ¹æ®è§†é¢‘ç”»é¢å’Œæ–‡æœ¬ä¸Šä¸‹æ–‡è¿›è¡Œæ¶ˆæ­§ï¼Œå¹¶è¯„ä¼° comprehensibilityã€‚

æ ¸å¿ƒåŸåˆ™ï¼š
1. **çŸ­è¯­ä¼˜å…ˆäºå•è¯**ï¼šå…ˆè¯†åˆ«çŸ­è¯­ï¼ˆå¦‚ "give up"ï¼‰ï¼Œå†è¯†åˆ«å•è¯ã€‚
2. **å¿…é¡»è°ƒç”¨å·¥å…·**ï¼šä¸è¦å‡­ç©ºç”Ÿæˆ fine_idï¼Œå¿…é¡»é€šè¿‡ query_fine_units è·å–å€™é€‰åˆ—è¡¨ã€‚
3. **å€™é€‰ä¸ºç©ºåˆ™è·³è¿‡**ï¼šå¦‚æœæ²¡æœ‰æŸ¥è¯¢åˆ°å€™é€‰ï¼Œä¸è¾“å‡ºè¯¥è¯çš„ annotationã€‚
4. **è¯„åˆ†è¦å®¢è§‚**ï¼šä»è¯­è¨€å­¦ä¹ è€…è§’åº¦è€ƒè™‘ï¼Œé«˜åˆ†è¡¨ç¤ºæ›´é€‚åˆå­¦ä¹ ã€‚
5. **JSON è¾“å‡º**ï¼šä¸¥æ ¼éµå¾ªæŒ‡å®šçš„ JSON Schema è¾“å‡ºç»“æœã€‚

è®°ä½ï¼š
- æ¯æ¬¡åªå¤„ç†ä¸€ä¸ª segmentã€‚
- Span æ˜¯ç›¸å¯¹äºè¯¥ segment æ–‡æœ¬çš„å­—ç¬¦åç§»ã€‚
"""

    def __init__(
        self,
        vertex: VertexClient,
        db: Database,
        lark: LarkClient,
        config: Config
    ):
        """
        åˆå§‹åŒ–ç¼–æ’å™¨

        Args:
            vertex: Vertex AI å®¢æˆ·ç«¯
            db: æ•°æ®åº“å®¢æˆ·ç«¯
            lark: Lark é€šçŸ¥å®¢æˆ·ç«¯
            config: ç³»ç»Ÿé…ç½®
        """
        self.vertex = vertex
        self.lark = lark
        self.config = config
        self.logger = get_logger(__name__)

        # åˆå§‹åŒ– MCP å·¥å…·
        self.mcp = MCPTools(db, config.gemini_model)

        # åˆå§‹åŒ–æ ‡æ³¨å™¨
        self.word_annotator = WordAnnotator()
        self.phrase_annotator = PhraseAnnotator()

    async def process_video(
        self,
        video_uid: str,
        video_uri: Optional[str],
        segments: list[dict]
    ) -> tuple[list[dict], str, str]:
        """
        å¤„ç†æ•´ä¸ªè§†é¢‘ï¼ˆä¸»å…¥å£ï¼‰

        Args:
            video_uid: è§†é¢‘å”¯ä¸€æ ‡è¯†
            video_uri: GCS è§†é¢‘ URIï¼ˆæˆ– None è¡¨ç¤ºçº¯æ–‡æœ¬æ¨¡å¼ï¼‰
            segments: WhisperX çš„ segments åˆ—è¡¨

        Returns:
            (annotations, method, ontology_ver) å…ƒç»„
            - annotations: æ ‡æ³¨åˆ—è¡¨
            - method: ä½¿ç”¨çš„æ–¹æ³•ï¼ˆ'gemini_video' | 'gemini_text' | 'gemini_nocache'ï¼‰
            - ontology_ver: æœ¬ä½“ç‰ˆæœ¬

        Raises:
            VertexError: Gemini API å®Œå…¨ä¸å¯ç”¨æ—¶
        """
        self.logger.info(
            f"å¼€å§‹å¤„ç†è§†é¢‘: {video_uid}, "
            f"segments={len(segments)}, "
            f"has_video={video_uri is not None}"
        )

        # 1. åˆ›å»ºç¼“å­˜å†…å®¹ï¼ˆå¸¦é™çº§ï¼‰
        cached_content, method = await self._create_cached_content_with_fallback(
            video_uri, segments
        )

        # 2. å¹¶å‘å¤„ç†æ‰€æœ‰ segments
        annotations = await self._process_segments_concurrent(
            cached_content, segments, video_uid
        )

        # 3. è¿”å›ç»“æœï¼ˆä½¿ç”¨å½“å‰ Gemini æ¨¡å‹ç‰ˆæœ¬ä½œä¸º ontology_verï¼‰
        ontology_ver = self.config.gemini_model

        self.logger.info(
            f"âœ“ è§†é¢‘å¤„ç†å®Œæˆ: {video_uid}, "
            f"annotations={len(annotations)}, "
            f"method={method}, "
            f"ontology_ver={ontology_ver}"
        )

        return annotations, method, ontology_ver

    async def _create_cached_content_with_fallback(
        self,
        video_uri: Optional[str],
        segments: list[dict]
    ) -> tuple[Optional[CachedContent], str]:
        """
        åˆ›å»ºç¼“å­˜å†…å®¹ï¼ˆå¸¦é™çº§ç­–ç•¥ï¼‰

        é™çº§é¡ºåºï¼š
        1. å¤šæ¨¡æ€ç¼“å­˜ï¼ˆè§†é¢‘ + æ–‡æœ¬ï¼‰
        2. çº¯æ–‡æœ¬ç¼“å­˜ï¼ˆä»…æ–‡æœ¬ï¼‰
        3. æ— ç¼“å­˜æ¨¡å¼

        Args:
            video_uri: GCS è§†é¢‘ URIï¼ˆæˆ– Noneï¼‰
            segments: Segments åˆ—è¡¨

        Returns:
            (cached_content, method) å…ƒç»„
        """
        # å°è¯• 1: å¤šæ¨¡æ€ç¼“å­˜
        if video_uri:
            try:
                self.logger.info("å°è¯•åˆ›å»ºå¤šæ¨¡æ€ç¼“å­˜...")
                cached_content = await self._create_cached_content(
                    video_uri, segments, multimodal=True
                )
                return cached_content, "gemini_video"
            except VertexError as e:
                self.logger.warning(f"å¤šæ¨¡æ€ç¼“å­˜åˆ›å»ºå¤±è´¥: {e}")
                # ç»§ç»­é™çº§

        # å°è¯• 2: çº¯æ–‡æœ¬ç¼“å­˜
        try:
            self.logger.info("åˆ›å»ºçº¯æ–‡æœ¬ç¼“å­˜...")
            cached_content = await self._create_cached_content(
                None, segments, multimodal=False
            )
            return cached_content, "gemini_text"
        except VertexError as e:
            self.logger.error(f"çº¯æ–‡æœ¬ç¼“å­˜ä¹Ÿå¤±è´¥: {e}")
            # ç»§ç»­é™çº§

        # å°è¯• 3: æ— ç¼“å­˜æ¨¡å¼
        self.logger.warning("é™çº§åˆ°æ— ç¼“å­˜æ¨¡å¼")
        return None, "gemini_nocache"

    async def _create_cached_content(
        self,
        video_uri: Optional[str],
        segments: list[dict],
        multimodal: bool
    ) -> CachedContent:
        """
        åˆ›å»ºç¼“å­˜å†…å®¹ï¼ˆåŒ…å«è§†é¢‘ã€æ–‡æœ¬å’Œtoolsï¼‰

        Args:
            video_uri: GCS è§†é¢‘ URIï¼ˆæˆ– Noneï¼‰
            segments: Segments åˆ—è¡¨
            multimodal: æ˜¯å¦å¤šæ¨¡æ€

        Returns:
            CachedContent å¯¹è±¡

        Raises:
            VertexError: åˆ›å»ºå¤±è´¥
        """
        # æ‹¼æ¥æ‰€æœ‰ segments
        full_transcript = "\n\n".join([
            f"Segment #{i} ({s['start']:.1f}s - {s['end']:.1f}s):\n{s['text']}"
            for i, s in enumerate(segments)
        ])

        # è·å–å·¥å…·å®šä¹‰ï¼ˆéœ€è¦åŒ…å«åœ¨ç¼“å­˜ä¸­ï¼‰
        tools = self.mcp.get_tool_definitions()

        # åˆ›å»ºç¼“å­˜ï¼ˆåŒ…å« tools å’Œ system_instructionï¼‰
        return await self.vertex.create_cached_content(
            video_uri=video_uri if multimodal else None,
            text_content=full_transcript,
            system_instruction=self.SYSTEM_INSTRUCTION,  # [æ–°å¢] ä¼ å…¥ç³»ç»ŸæŒ‡ä»¤
            tools=tools,  # åŒ…å«å·¥å…·å®šä¹‰
            ttl_seconds=self.config.gemini_cache_ttl_seconds
        )

    async def _process_segments_concurrent(
        self,
        cached_content: Optional[CachedContent],
        segments: list[dict],
        video_uid: str
    ) -> list[dict]:
        """
        å¹¶å‘å¤„ç†æ‰€æœ‰ segments

        Args:
            cached_content: ç¼“å­˜å†…å®¹ï¼ˆæˆ– Noneï¼‰
            segments: Segments åˆ—è¡¨
            video_uid: è§†é¢‘ UID

        Returns:
            æ‰€æœ‰ annotations çš„èšåˆåˆ—è¡¨
        """
        semaphore = asyncio.Semaphore(self.config.gemini_max_concurrency)

        async def process_one(idx: int, segment: dict):
            """å¤„ç†å•ä¸ª segmentï¼ˆå…ˆçŸ­è¯­åå•è¯ï¼‰"""
            async with semaphore:
                try:
                    all_anns = []

                    # 1. å¤„ç†çŸ­è¯­
                    phrase_anns = await self._process_segment(
                        cached_content=cached_content,
                        segment=segment,
                        segment_index=idx,
                        annotator=self.phrase_annotator,
                        video_uid=video_uid
                    )
                    all_anns.extend(phrase_anns)

                    # 2. å¤„ç†å•è¯
                    word_anns = await self._process_segment(
                        cached_content=cached_content,
                        segment=segment,
                        segment_index=idx,
                        annotator=self.word_annotator,
                        video_uid=video_uid
                    )
                    all_anns.extend(word_anns)

                    return all_anns

                except Exception as e:
                    self.logger.error(f"Segment {idx} å¤„ç†å¤±è´¥: {e}")

                    # å‘é€é”™è¯¯é€šçŸ¥
                    await self.lark.send_error(
                        error_type="Segment å¤„ç†å¤±è´¥",
                        error_message=str(e),
                        context={
                            "è§†é¢‘ UID": video_uid,
                            "Segment #": idx,
                            "Segment æ–‡æœ¬": segment.get("text", "")[:100]
                        }
                    )

                    return []

        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [
            process_one(idx, seg)
            for idx, seg in enumerate(segments)
        ]

        # å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*tasks)

        # åˆå¹¶ç»“æœ
        all_annotations = []
        for batch in results:
            all_annotations.extend(batch)

        self.logger.info(
            f"å¹¶å‘å¤„ç†å®Œæˆ: {len(segments)} segments, "
            f"{len(all_annotations)} annotations"
        )

        return all_annotations

    async def _process_segment(
        self,
        cached_content: Optional[CachedContent],
        segment: dict,
        segment_index: int,
        annotator: BaseAnnotator,
        video_uid: str
    ) -> list[dict]:
        """
        å¤„ç†å•ä¸ª segmentï¼ˆä½¿ç”¨æŒ‡å®šçš„æ ‡æ³¨å™¨ï¼‰

        Args:
            cached_content: ç¼“å­˜å†…å®¹ï¼ˆæˆ– Noneï¼‰
            segment: Segment æ•°æ®
            segment_index: Segment ç´¢å¼•
            annotator: æ ‡æ³¨å™¨å®ä¾‹
            video_uid: è§†é¢‘ UID

        Returns:
            è¯¥ segment çš„ annotations åˆ—è¡¨
        """
        # [ä¿®æ”¹] ç§»é™¤äº†åŸæœ‰çš„ system_instruction å®šä¹‰ï¼Œç°åœ¨å·²ç»åœ¨ Cache é‡Œäº†

        # æ„å»ºå…·ä½“çš„ä»»åŠ¡æŒ‡ä»¤
        task_instruction = f"""
ç°åœ¨è¯·å¤„ç† Segment #{segment_index}ï¼š
æ—¶é—´: {segment['start']:.1f}s - {segment['end']:.1f}s
æ–‡æœ¬: {segment['text']}

è¯·ä½¿ç”¨ **{annotator.get_kind()}** æ¨¡å¼è¿›è¡Œåˆ†æã€‚
"""

        # æ„å»ºå®Œæ•´ promptï¼ˆä»»åŠ¡æŒ‡ä»¤ + æ ‡æ³¨å™¨ç‰¹å®š Promptï¼‰
        prompt = task_instruction + "\n\n" + annotator.build_prompt(segment, segment_index)

        # è·å–å·¥å…·å®šä¹‰
        tools = self.mcp.get_tool_definitions()

        # åˆ›å»º trace_id
        trace_id = f"[{video_uid}|Seg#{segment_index}|{annotator.get_kind()}]"

        # åˆ›å»º tool_handlerï¼ˆå¸¦é€šçŸ¥é€»è¾‘å’Œè¯¦ç»†æ—¥å¿—ï¼‰
        async def tool_handler_with_notification(function_name: str, args: dict) -> dict:
            """
            MCP å·¥å…·è°ƒç”¨å¤„ç†å™¨ï¼ˆå¸¦é€šçŸ¥é€»è¾‘ï¼‰

            èŒè´£ï¼š
            1. è°ƒç”¨ MCP æŸ¥è¯¢
            2. åˆ¤æ–­æ˜¯å¦éœ€è¦é€šçŸ¥
            3. è¿”å›å€™é€‰åˆ—è¡¨ç»™ Gemini
            """
            if function_name == "query_fine_units":
                # è®°å½•æŸ¥è¯¢å‚æ•°
                lemma = args.get("lemma", "N/A")
                kind = args.get("kind", "N/A")
                pos = args.get("pos", "N/A")

                # æŸ¥è¯¢æ•°æ®åº“
                result = await self.mcp.query_fine_units(**args)

                # è®°å½•æŸ¥è¯¢ç»“æœ
                if result.found:
                    self.logger.info(
                        f"      âœ… æŸ¥è¯¢ \"{lemma}\" (kind={kind}, pos={pos}) â†’ æ‰¾åˆ° {len(result.candidates)} ä¸ªå€™é€‰:"
                    )
                    # è®°å½•æ¯ä¸ªå€™é€‰çš„è¯¦æƒ…
                    for cand_idx, cand in enumerate(result.candidates):
                        fine_id = cand.get("fine_id", "N/A")
                        definition = cand.get("definition", "N/A")[:120]  # æˆªå–å®šä¹‰
                        self.logger.info(
                            f"         [{cand_idx+1}] fine_id={fine_id} | def: \"{definition}\""
                        )
                else:
                    self.logger.warning(
                        f"      âŒ æŸ¥è¯¢ \"{lemma}\" (kind={kind}, pos={pos}) â†’ æœªæ‰¾åˆ°å€™é€‰"
                    )
                    # å‘é€é€šçŸ¥
                    await self._handle_not_found(
                        query_params=result.query_params,
                        video_uid=video_uid,
                        segment_index=segment_index,
                        segment=segment
                    )

                # è¿”å›å€™é€‰åˆ—è¡¨ç»™ Geminiï¼ˆåŒæ—¶è¿”å› lemma ç”¨äºæ—¥å¿—æ˜ å°„ï¼‰
                return {
                    "candidates": result.candidates,
                    "lemma": lemma  # ç”¨äº vertex.py å»ºç«‹ fine_id â†’ lemma æ˜ å°„
                }

            elif function_name == "create_fine_unit":
                # åˆ›å»ºæ–°çš„ fine_unit
                lemma = args.get("lemma", "N/A")
                kind = args.get("kind", "N/A")
                pos = args.get("pos", "N/A")
                definition = args.get("definition", "N/A")

                self.logger.info(
                    f"      ğŸ—ï¸ Gemini å°è¯•åˆ›å»º fine_unit: \"{lemma}\" (kind={kind}, pos={pos})"
                )
                self.logger.info(f"         ğŸ“ å®šä¹‰: {definition}")

                # è°ƒç”¨ MCP åˆ›å»º
                result = await self.mcp.create_fine_unit(
                    lemma=lemma,
                    kind=kind,
                    pos=pos,
                    definition=definition,
                    lang=args.get("lang", "en"),
                    video_uid=video_uid
                )

                self.logger.info(
                    f"      ğŸ’ Fine unit åˆ›å»ºç»“æœ: fine_id={result['fine_id']}, "
                    f"status={result['status']}, note={result['note']}"
                )

                # è¿”å›åˆ›å»ºçš„å€™é€‰ï¼ˆæ ¼å¼ä¸ query_fine_units ä¿æŒä¸€è‡´ï¼‰
                return {
                    "candidates": [{
                        "fine_id": result["fine_id"],
                        "label": result["lemma"],
                        "pos": result["pos"],
                        "definition": result["def"]
                    }],
                    "lemma": lemma
                }

            else:
                raise ValueError(f"Unknown function: {function_name}")

        # è°ƒç”¨ Gemini
        try:
            response = await self.vertex.call_with_tools(
                cached_content=cached_content,
                prompt=prompt,
                tools=tools,
                tool_handler=tool_handler_with_notification,
                # [æ–°å¢] ä»…å½“æ²¡æœ‰ Cache æ—¶ï¼Œæ‰‹åŠ¨ä¼ å…¥ system_instruction
                system_instruction=self.SYSTEM_INSTRUCTION if not cached_content else None,
                generation_config={
                    "response_mime_type": "application/json",
                    "response_schema": annotator.get_output_schema()
                },
                # [æ–°å¢] ä¼ å…¥è¿½è¸ªä¸Šä¸‹æ–‡ï¼ˆä»…ç”¨äºæ—¥å¿—ï¼ŒLLMçœ‹ä¸åˆ°ï¼‰
                trace_context={
                    "video_uid": video_uid,
                    "segment_index": segment_index,
                    "segment_text": segment["text"],
                    "annotator_kind": annotator.get_kind()
                }
            )

            annotations = response.get("annotations", [])

            # éªŒè¯å’Œè¿‡æ»¤
            valid_anns = []
            for ann in annotations:
                if annotator.validate_annotation(ann, segment):
                    valid_anns.append(ann)
                else:
                    self.logger.warning(
                        f"Segment {segment_index} çš„ annotation éªŒè¯å¤±è´¥: {ann}"
                    )

            self.logger.debug(
                f"Segment {segment_index} ({annotator.get_kind()}): "
                f"{len(valid_anns)}/{len(annotations)} annotations æœ‰æ•ˆ"
            )

            return valid_anns

        except VertexError as e:
            self.logger.error(
                f"Segment {segment_index} ({annotator.get_kind()}) "
                f"Gemini è°ƒç”¨å¤±è´¥: {e}"
            )

            # å‘é€é”™è¯¯é€šçŸ¥
            await self.lark.send_error(
                error_type="Gemini API è°ƒç”¨å¤±è´¥",
                error_message=str(e),
                context={
                    "è§†é¢‘ UID": video_uid,
                    "Segment #": segment_index,
                    "æ ‡æ³¨å™¨": annotator.get_kind()
                }
            )

            return []

    async def _handle_not_found(
        self,
        query_params: dict,
        video_uid: str,
        segment_index: int,
        segment: dict
    ):
        """
        å¤„ç†æœªæ‰¾åˆ°çš„æƒ…å†µï¼ˆå†³å®šæ˜¯å¦é€šçŸ¥ï¼‰

        ä¸šåŠ¡è§„åˆ™ï¼š
        - çŸ­è¯­æœªæ‰¾åˆ° â†’ ä¸€å®šé€šçŸ¥
        - å•è¯æœªæ‰¾åˆ° â†’ ä¸€å®šé€šçŸ¥
        ï¼ˆåªè¦ LLM å°è¯•æŸ¥è¯¢äº†ï¼Œå°±è¯´æ˜å®ƒè®¤ä¸ºé‡è¦ï¼Œåº”è¯¥é€šçŸ¥ï¼‰

        Args:
            query_params: æŸ¥è¯¢å‚æ•° {lemma, kind, pos, lang}
            video_uid: è§†é¢‘ UID
            segment_index: Segment ç´¢å¼•
            segment: Segment æ•°æ®
        """
        kind = query_params["kind"]
        lemma = query_params["lemma"]
        lang = query_params["lang"]

        if kind == "phrase_sense":
            # çŸ­è¯­æœªæ‰¾åˆ° â†’ é€šçŸ¥
            self.logger.warning(
                f"âŒ çŸ­è¯­æœªåŒ¹é…: '{lemma}' | "
                f"video={video_uid} | segment={segment_index}"
            )

            await self.lark.send_phrase_not_found(
                phrase=lemma,
                lang=lang,
                video_uid=video_uid,
                segment_index=segment_index,
                segment_text=segment["text"],
                timestamp_range=f"{segment['start']:.1f}s - {segment['end']:.1f}s"
            )

        elif kind == "word_sense":
            # å•è¯æœªæ‰¾åˆ° â†’ é€šçŸ¥ï¼ˆLLM å°è¯•æŸ¥è¯¢äº†ï¼Œè¯´æ˜å®ƒè®¤ä¸ºé‡è¦ï¼‰
            self.logger.warning(
                f"âŒ å•è¯æœªåŒ¹é…: '{lemma}' (pos={query_params.get('pos')}) | "
                f"video={video_uid} | segment={segment_index}"
            )

            await self.lark.send_word_not_found(
                word=lemma,
                pos=query_params.get("pos"),
                lang=lang,
                video_uid=video_uid,
                segment_index=segment_index,
                segment_text=segment["text"]
            )

        else:
            # æœªçŸ¥ç±»å‹
            self.logger.warning(f"æœªçŸ¥çš„ kind: {kind}")